{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 45s 0us/step\n",
      "Training data shape: (50000, 32, 32, 3)\n",
      "Training labels shape: (50000, 1)\n",
      "Test data shape: (10000, 32, 32, 3)\n",
      "Test labels shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Print dataset shapes\n",
    "print(\"Training data shape:\", x_train.shape)  # (50000, 32, 32, 3)\n",
    "print(\"Training labels shape:\", y_train.shape)  # (50000, 1)\n",
    "print(\"Test data shape:\", x_test.shape)  # (10000, 32, 32, 3)\n",
    "print(\"Test labels shape:\", y_test.shape)  # (10000, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59  62  63]\n",
      "   [ 43  46  45]\n",
      "   [ 50  48  43]\n",
      "   ...\n",
      "   [158 132 108]\n",
      "   [152 125 102]\n",
      "   [148 124 103]]\n",
      "\n",
      "  [[ 16  20  20]\n",
      "   [  0   0   0]\n",
      "   [ 18   8   0]\n",
      "   ...\n",
      "   [123  88  55]\n",
      "   [119  83  50]\n",
      "   [122  87  57]]\n",
      "\n",
      "  [[ 25  24  21]\n",
      "   [ 16   7   0]\n",
      "   [ 49  27   8]\n",
      "   ...\n",
      "   [118  84  50]\n",
      "   [120  84  50]\n",
      "   [109  73  42]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[208 170  96]\n",
      "   [201 153  34]\n",
      "   [198 161  26]\n",
      "   ...\n",
      "   [160 133  70]\n",
      "   [ 56  31   7]\n",
      "   [ 53  34  20]]\n",
      "\n",
      "  [[180 139  96]\n",
      "   [173 123  42]\n",
      "   [186 144  30]\n",
      "   ...\n",
      "   [184 148  94]\n",
      "   [ 97  62  34]\n",
      "   [ 83  53  34]]\n",
      "\n",
      "  [[177 144 116]\n",
      "   [168 129  94]\n",
      "   [179 142  87]\n",
      "   ...\n",
      "   [216 184 140]\n",
      "   [151 118  84]\n",
      "   [123  92  72]]]\n",
      "\n",
      "\n",
      " [[[154 177 187]\n",
      "   [126 137 136]\n",
      "   [105 104  95]\n",
      "   ...\n",
      "   [ 91  95  71]\n",
      "   [ 87  90  71]\n",
      "   [ 79  81  70]]\n",
      "\n",
      "  [[140 160 169]\n",
      "   [145 153 154]\n",
      "   [125 125 118]\n",
      "   ...\n",
      "   [ 96  99  78]\n",
      "   [ 77  80  62]\n",
      "   [ 71  73  61]]\n",
      "\n",
      "  [[140 155 164]\n",
      "   [139 146 149]\n",
      "   [115 115 112]\n",
      "   ...\n",
      "   [ 79  82  64]\n",
      "   [ 68  70  55]\n",
      "   [ 67  69  55]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[175 167 166]\n",
      "   [156 154 160]\n",
      "   [154 160 170]\n",
      "   ...\n",
      "   [ 42  34  36]\n",
      "   [ 61  53  57]\n",
      "   [ 93  83  91]]\n",
      "\n",
      "  [[165 154 128]\n",
      "   [156 152 130]\n",
      "   [159 161 142]\n",
      "   ...\n",
      "   [103  93  96]\n",
      "   [123 114 120]\n",
      "   [131 121 131]]\n",
      "\n",
      "  [[163 148 120]\n",
      "   [158 148 122]\n",
      "   [163 156 133]\n",
      "   ...\n",
      "   [143 133 139]\n",
      "   [143 134 142]\n",
      "   [143 133 144]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   ...\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 253 253]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113 120 112]\n",
      "   [111 118 111]\n",
      "   [105 112 106]\n",
      "   ...\n",
      "   [ 72  81  80]\n",
      "   [ 72  80  79]\n",
      "   [ 72  80  79]]\n",
      "\n",
      "  [[111 118 110]\n",
      "   [104 111 104]\n",
      "   [ 99 106  98]\n",
      "   ...\n",
      "   [ 68  75  73]\n",
      "   [ 70  76  75]\n",
      "   [ 78  84  82]]\n",
      "\n",
      "  [[106 113 105]\n",
      "   [ 99 106  98]\n",
      "   [ 95 102  94]\n",
      "   ...\n",
      "   [ 78  85  83]\n",
      "   [ 79  85  83]\n",
      "   [ 80  86  84]]]\n",
      "\n",
      "\n",
      " [[[ 28  25  10]\n",
      "   [ 37  34  19]\n",
      "   [ 38  35  20]\n",
      "   ...\n",
      "   [ 76  67  39]\n",
      "   [ 81  72  43]\n",
      "   [ 85  76  47]]\n",
      "\n",
      "  [[ 33  28  13]\n",
      "   [ 34  30  14]\n",
      "   [ 32  27  12]\n",
      "   ...\n",
      "   [ 95  82  55]\n",
      "   [ 96  82  56]\n",
      "   [ 85  72  45]]\n",
      "\n",
      "  [[ 39  32  15]\n",
      "   [ 40  33  17]\n",
      "   [ 57  50  33]\n",
      "   ...\n",
      "   [ 93  76  52]\n",
      "   [107  89  66]\n",
      "   [ 95  77  54]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 83  73  52]\n",
      "   [ 87  77  56]\n",
      "   [ 84  74  52]\n",
      "   ...\n",
      "   [ 99  93  70]\n",
      "   [ 90  84  61]\n",
      "   [ 81  75  52]]\n",
      "\n",
      "  [[ 88  72  51]\n",
      "   [ 90  74  52]\n",
      "   [ 93  77  56]\n",
      "   ...\n",
      "   [ 80  74  53]\n",
      "   [ 76  70  49]\n",
      "   [ 82  76  55]]\n",
      "\n",
      "  [[ 97  78  56]\n",
      "   [ 94  75  53]\n",
      "   [ 93  75  53]\n",
      "   ...\n",
      "   [ 54  47  28]\n",
      "   [ 63  56  37]\n",
      "   [ 72  65  46]]]\n",
      "\n",
      "\n",
      " [[[170 180 198]\n",
      "   [168 178 196]\n",
      "   [177 185 203]\n",
      "   ...\n",
      "   [162 179 215]\n",
      "   [158 178 214]\n",
      "   [157 177 212]]\n",
      "\n",
      "  [[168 181 198]\n",
      "   [172 185 201]\n",
      "   [171 183 200]\n",
      "   ...\n",
      "   [159 177 212]\n",
      "   [156 176 211]\n",
      "   [154 174 209]]\n",
      "\n",
      "  [[154 170 186]\n",
      "   [149 165 181]\n",
      "   [129 144 162]\n",
      "   ...\n",
      "   [161 178 214]\n",
      "   [157 177 212]\n",
      "   [154 174 209]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 74  84  80]\n",
      "   [ 76  85  81]\n",
      "   [ 78  85  82]\n",
      "   ...\n",
      "   [ 71  75  78]\n",
      "   [ 68  72  75]\n",
      "   [ 61  65  68]]\n",
      "\n",
      "  [[ 68  76  77]\n",
      "   [ 69  77  78]\n",
      "   [ 72  79  78]\n",
      "   ...\n",
      "   [ 76  80  83]\n",
      "   [ 71  75  78]\n",
      "   [ 71  75  78]]\n",
      "\n",
      "  [[ 67  75  78]\n",
      "   [ 68  76  79]\n",
      "   [ 69  75  76]\n",
      "   ...\n",
      "   [ 75  79  82]\n",
      "   [ 71  75  78]\n",
      "   [ 73  77  80]]]]\n",
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " [4]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 rows of the training data\n",
    "print(x_train[:5])\n",
    "\n",
    "# Print the first 5 labels of the training data\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 74s 81ms/step - loss: 1.5875 - accuracy: 0.4226\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 59s 76ms/step - loss: 1.2420 - accuracy: 0.5613\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 1.0990 - accuracy: 0.6150\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 59s 75ms/step - loss: 1.0222 - accuracy: 0.6422\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 60s 76ms/step - loss: 0.9661 - accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 0.9248 - accuracy: 0.6791\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 53s 67ms/step - loss: 0.8889 - accuracy: 0.6913\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 55s 70ms/step - loss: 0.8594 - accuracy: 0.7010\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 52s 67ms/step - loss: 0.8362 - accuracy: 0.7092\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 54s 69ms/step - loss: 0.8154 - accuracy: 0.7169\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.9053 - accuracy: 0.6868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9053444266319275, 0.6868000030517578]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional Neural Network using 2 layers of conv2D and then giving the output to a dense layer\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "#1st output =  [0.9055706858634949, 0.7009999752044678] # 70.1% accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
